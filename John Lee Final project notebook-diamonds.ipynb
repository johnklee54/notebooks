{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "## Diamonds\n",
    "\n",
    "This is a regression model built to predict a diamond's price based on different characteristics of a diamond. \n",
    "\n",
    "It starts with simple linear regression model. The model will try to use a single indepdent variable (in this case the carat size) to predict a dependent variable (price of the diamond) as this seems to make sense, the larger the carat size the more expensive it should be. \n",
    "\n",
    "Using the data provided by Kaggle, the data is a single comma-seprated file (csv) with the following characteristics:\n",
    "\n",
    "- A data frame with 53940 rows and 10 variables:\n",
    "- price: price in US dollars (\\$326--\\$18,823)\n",
    "- carat: weight of the diamond (0.2--5.01)\n",
    "- cut: quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n",
    "- color: diamond colour, from J (worst) to D (best)\n",
    "- clarity: a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
    "- x: length in mm (0--10.74)\n",
    "- y: width in mm (0--58.9)\n",
    "- z: depth in mm (0--31.8)\n",
    "- depth: total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79)\n",
    "- table: width of top of diamond relative to widest point (43--95)\n",
    "\n",
    "Further description and download link can be found in the [references](#references) section of this notebook\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Importing the libraries needed to process the data and the regression model\n",
    "\n",
    "pandas - Python library used to process data. We will put the data into a pandas data frame for ease of use.\n",
    "matplotlib - library used to generate a plot in Python. we will generate a scatter plot and the regression line using this library\n",
    "Sklearn - this is the libary used for machine learning in Python. It is called scikitl-learn. It contains the functions and methods to:\n",
    "- Split data to train and test\n",
    "- Linear regression test\n",
    "- Metrics to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Importing libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Importing the data and defining the columns. \n",
    "Referring to the documentation from Kaggle, and reviewing the csv file to find the format of the data is important\n",
    "- The columns are defined \n",
    "- The variable Diamond is used to point to the data read into memory using pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Defining the columns of and reading the DataFrame \n",
    "#columns = ['carat',\t'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x' ,'y', 'z']\n",
    "Diamond = pd.read_csv('diamonds.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Exploring the data frame\n",
    "Exploring the data frame created will ensure our data looks good, we can get some descriptions from the data by using the following methods\n",
    "\n",
    "\n",
    "- .info() - prints information about the data such as \n",
    "    - number of columns\n",
    "    - column labels\n",
    "    - data types **\n",
    "    - range index - how many rows of data\n",
    "A good way to get some statistics on the data we are using\n",
    "- .describe() - quick calculation of the data \n",
    "    - count - not empty values\n",
    "    - mean - average\n",
    "    - std - standard deviation\n",
    "    - min - minimum value\n",
    "    - 25% - 25% percentile\n",
    "    - 50% - 50% percentile\n",
    "    - 75% - 75% percential\n",
    "    - max - maximum value\n",
    "\n",
    "** As shown in the output of .info()  the data returned three types, int64, float64 and object. Since regression can only use numeric data, we should be aware cut, color, clarity cannot be used as it. More on this later in the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Printing some information about the data using .info():\\n\")\n",
    "Diamond.info()\n",
    "print(\"\\n The data description using .describe():\")\n",
    "Diamond.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small snapshot of the data using the .head() method\n",
    "- .head() - method in pandas used to return a few rows of the data. If a number is not specified, return the first 5 rows. We will use this again later for data comparision. Notice cut color and categoric features (non-numeric) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Printing 5 rows of the data:\")\n",
    "Diamond.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make sure this data is complete and does not have any missing values. Using the .isna() will show any missing values denoted as NaN  by Pandas\n",
    "\n",
    "All zeros in the right column means there is data in each row for the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Diamond['price'].value_counts()\n",
    "Diamond.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the cross correlation matrix. - Since we only want to do a simple regression test, we want to try the find the independant variable that is closest to the price of the diamond. By running the .corr() method , Pandas will show us how the relationship between the columns in the dataframe. The higher the number the closer the columns are related to each other. Only numeric values are shown in this matrix. We will look at the categorical (non-numeric) data later in part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the cross-correlation matrix - Looking for two correlated values. \n",
    "print(Diamond.corr(numeric_only = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The correlation matrix above shows that price is closely related to carat which indicates this may be a good relationship to use for our regresssion model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Assigning the X and y \n",
    "We need the independent variable and dependent variables assigned. X is independent and y is dependent. we are going to use X to predict y\n",
    "X = adding carat to the feature matrix\n",
    "y = adding price as the target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Assigning our feature matrix (X) and target varaible (y)\n",
    "#Using the carat of the diamond to predict the price\n",
    "X = Diamond[['carat']]\n",
    "y = Diamond['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 Dividing the data into two sets\n",
    "we want to take our data and divide it into two sets, train and test. We will use our train set to train the model and use the test set afterwards. 70% of the data will be used to train the model with 30% used as the test data set.  Using a the random_state option sets a seed so that we can recreate the same test with same results. shuffle will shuffle the data before it splits so we get a good representation of the data without introducing a bias such as order of the data into our sets. train_test_split(0 is a function of scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Dividing the dataset into test and train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 Training the Linear Regression Model\n",
    "We train the model using the LinearRegression() function from scikit_learn. We are using the training set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Selecting the linear regression method from the scikit-learn library\n",
    "model = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6  Predicting the Diamond price\n",
    "\n",
    "Using the .predict() from scikit-learn, we are predicting y based on the X Training set as well as y based on the X test set. This will allow us to calculate the performance of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Preciting the diamonds price from training and test data\n",
    "y_prediction_train = model.predict(X_train)\n",
    "y_prediction_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 Evaluating the performance of the model.\n",
    "We predicted the diamond's price in step 6. We want to see how it performs. We are going to use the R2 score and the Mean Absolute Error (MAE) as indications of how well our model can predict the price of a diamond using only the carat size.\n",
    "\n",
    "Interpreting the R2 score we can see how well our model fit the data. the percentage of the variance in the dependent variable that the independant variable explains. In other words how accurate to predict the price of the diamond using the carat size. The closer to 1 theoretically the better the model fit. \n",
    "\n",
    "MAE will show us how \"off\" our model is. Because the diamond prices can vary and are dependent on its characteristics, we considered using MAE because it is  less sensitve to outliers. The lower the MAE, the closer the predictions are to the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7:  Evaluation\n",
    "# Evaluating the trained model on training data\n",
    "\n",
    "print(f\"The average carat size of diamonds in data {Diamond['carat'].mean()}\")\n",
    "print(f\"The average price of diamonds in the data {Diamond['price'].mean()}\")\n",
    "\n",
    "print (\"R2 score on train data= \",metrics.r2_score(y_train,y_prediction_train))\n",
    "print (\"R2 score on test data= \",metrics.r2_score(y_test,y_prediction_test))\n",
    "print(\"MAE on train data= \" , metrics.mean_absolute_error(y_train, y_prediction_train))\n",
    "print(\"MAE on test data = \" , metrics.mean_absolute_error(y_test, y_prediction_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 Graphing the data and regression line\n",
    "We will use matplotlib to produce a scatter plot of both sets of data and also plot the regeression line for both test and train data sets.  Reference lines for the average carat size (X) and price (y) were added as an observation point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test, y_test, color='b', label='Actual Data')\n",
    "plt.plot(X_test, y_prediction_test, color='r', label='Regression Line')\n",
    "plt.axvline(x=np.nanmean(X_test),color='c',linestyle='--', label ='Avg Carat Size \\'X test\\'')\n",
    "plt.axhline(y=np.nanmean(y_test),color='g',linestyle='--', label ='Avg price \\'y test\\'')\n",
    "plt.xlabel('Carat Size')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.title('Linear Regression Test Data')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(X_train, y_train, color='b', label='Training Data')\n",
    "plt.plot(X_train, y_prediction_train, color='r', label='Regression Line')\n",
    "plt.axvline(x=np.nanmean(X_train),color='c',linestyle='--', label ='Avg Carat Size \\'X train\\'')\n",
    "plt.axhline(y=np.nanmean(y_train),color='g',linestyle='--', label ='Avg price \\'y train\\'')\n",
    "plt.xlabel('Carat Size')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.title('Linear Regression Training Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For and easy reference, we created a dataframe using the actual values of price and carat size from the data and the predicted value from the regression model. This is an easy way to visually examine the accuracy of the model. As mentioned in step 3, we will use .head() to print out the first 25 rows of the data. Alternatively, we can use .iloc[] in pandas to select a range of rows to print out. The code box below has commented instruction to use .iloc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#put the data into a dataframe to compare actual and predicted values, print 25 rows\n",
    "#comparison_df = pd.DataFrame({\"Actual\":y_test, \"Predicted\":y_prediction_test}) \n",
    "\n",
    "comparison_df = pd.DataFrame({\"Carat\": X_test['carat'], \"Actual y\":y_test, \"Predicted y \":y_prediction_test}) \n",
    "comparison_df.head(25)\n",
    "\n",
    "# comment out the line above and uncomment the line below to print different sections of the dataframe. Adjust the range for the section of data to print. \n",
    "#print (comparison_df.iloc[25:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results \n",
    "Our results above indicates a fairly decent accurate model based soley on the carat size to predict the price. \n",
    "We can look at a graph above and also a sampling of what the data looks like.  The R2 score indicates this would be a fairly accurate model. The MAE indicated our model is off about ~1000 average.   The intersection of the mean of X and mean of y directly on the regression line also indicates a fairly accurate mode since the intersection point represents the value of y when X is at its average. However, there are some variances in accuracy. We can see some predicted values are within twenty dollars on some diamonds and off by thousands on others.   We will try to perform a multiple regression below to see if the model is more accurate when including other features.  We will look at the R2 and MAE as an indication to see if our model is more accurate when using a larger feature matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Regression\n",
    "Since our model above had some larger variances in the results, can we get the model to be more accurate? One way we can try to do this is to include more features in the data and see if these additional features affect the accuracy of the model.  We will use a multiple regression for this. \n",
    "To keep the dataframes separate, we will import the data into a different dataframe called M_diamond.  We will also have to prepare the data to include the categorical features cut, color , clarity as these seem important when deciding the price of a diamond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: reading the DataFrame and printing a few lines data fraome. \n",
    "\n",
    "M_diamond = pd.read_csv('diamonds.csv')\n",
    "M_diamond.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The column 'Unnamed: 0' isn't necessary as it seems like it is just a row indicator. The dataframe will also have a column to indicated the rows, so we will drop this column from the dataframe as we do not want to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the Unnamed: 0 column\n",
    "M_diamond.drop('Unnamed: 0', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "This time we need to prepare the data by converting the categorical features into numerical values. In order to do this, we will essentially take the unique answers from each of the columns (color and clarity) and create additional columns in the dataframes with the unique answers. After the columns are created, for each diamond,  we will populate the appropriate cell with a 1 to indicate which of the characteristics the diamond has.\n",
    "\n",
    "For example, take the color of a diamond. Each diamond is graded against a scale which contains seven colors (E,I,J,H,F,G,D).  We wiill expand the dataframe to include one column for each of the color grades. if I diamond is graded an 'E' in color, the dataframe will contain a '1' in the new 'E' column and '0' for the other columns (I,J,H,F,G,D). This ensures we have accounted for the color with a numberic value. We will apply the same concept for clarity by expanding the dataframe with an additional eight columns (one for each clarity grade).\n",
    "\n",
    "Since the cut rating of a diamond is ordinal (hierarchal scale) we will convert this column to a numerical scale from 0 - 4 as follows:\n",
    "\n",
    "- Fair = 0\n",
    "- Good - 1\n",
    "- Very Good = 2\n",
    "- Premium = 3\n",
    "- Ideal = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking to identify the columns which contain categorical features. \n",
    "M_diamond.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code box below, we are iterating through the data frame columns which contain objects as datatypes\n",
    "the for loop controls the iteration for each column. The if statement will print the column name and the unique values in the column if the column's datatype is 'object'\n",
    "\n",
    "This will give us the unique names we need to add the columns for color and clarity. It also shows the unique values for the rating scale for cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in M_diamond:\n",
    "    if M_diamond[col].dtypes=='object':\n",
    "        print(f'{col} : {M_diamond[col].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code box below is using  one-hot encoding to convert each of the unique values we identified above to boolean datatype. This technique involves using a new dataframe called dummies below and  using the 'get_dummies' function from Pandas.  As noted above, we will peform this for the 'color' and 'clarity' columns.\n",
    "\n",
    "The concept of Multicollinearity can occur when using the one-hot encoding. This means that two or more of the new independent variables we are creating have a high correlation with one another in the model which makes it difficult to identify the effect of each variable's effect on the dependent variable. They are simply too closely related. when using dummy variables the dummy variable trap can occur in which one dummy variable can be predicted from the others. We will drop one of the dummy variables. the 'drop_first = True' option below will drop the first level of variable. Comparre the output of 'dummies.dtypes' below to the unique object values from above. One unique value was dropped from 'cut' and one from 'clarity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(M_diamond[['color','clarity']],drop_first=True)\n",
    "dummies.dtypes, print(f\"A few lines of the new dataframe \\n {dummies.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the header output above, we can see the results of the 'get_dummies' function created the new boolean columns, but the values are not numeric. The values in the columns are set the \"True\" if the diamond in the row is rated a particular color or clarity rating and 'False' for the remaining respective columns. The next codebox uses the .replace() method to replace 'True' with a '1' and 'False' with a '0' and set the type as integer. This is the final step for color and clarity columns. observe the output from the box below. All of the values are now '1' or '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in dummies:\n",
    "    dummies[col] = dummies[col].replace({'True':1,'False':0}).astype(int)\n",
    "    \n",
    "dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dummies dataframe is complete for color and clarity, we will now concatenate the dummies df with our M_diamond dataframe. Also drop the categorical 'color' and 'clarity' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the two dataframes together as noted in above Markdown box. \n",
    "M_diamond = pd.concat([M_diamond,dummies],axis=1)\n",
    "M_diamond.drop(['color','clarity'],axis=1,inplace=True)\n",
    "M_diamond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final column to fix is to replace the cut column with a numeric scale. \n",
    "We first look at the unique values in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_diamond.cut.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use .replace() again to replace the values as follows:\n",
    "- Fair = 0\n",
    "- Good - 1\n",
    "- Very Good = 2\n",
    "- Premium = 3\n",
    "- Ideal = 4\n",
    "\n",
    "We print the info for the dataframe to confirm all columns are now numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the values in cut with numeric scale and disply the data type for each column\n",
    "M_diamond['cut'] = M_diamond['cut'].replace({'Fair':0,'Good':1,'Very Good':2,'Premium':3,'Ideal':4})\n",
    "M_diamond.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the cross-correlation matrix - Looking for additional  correlated values. \n",
    "print(M_diamond.corr(numeric_only = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Assigning the X and y \n",
    "We need the independent variable and dependent variables reassigned. X is independent and y is dependent. we are going to use X to predict y\n",
    "X = drop the price column and use all of the remaining columns. This increases the feature matrix from the previous simple regression. \n",
    "y = adding price as the target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Seperating the data into features and labels\n",
    "\n",
    "X = M_diamond.drop('price',axis=1) # Independent variable\n",
    "y = M_diamond['price'] # dependent variable\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 Dividing the data into two sets\n",
    "we want to take our data and divide it into two sets, train and test. We will use our train set to train the model and use the test set afterwards. 70% of the data will be used to train the model with 30% used as the test data set.  Using a the random_state option sets a seed so that we can recreate the same test with same results. shuffle will shuffle the data before it splits so we get a good representation of the data without introducing a bias such as order of the data into our sets. train_test_split(0 is a function of scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Dividing the dataset into test and train data\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.3, random_state=10, shuffle=True)\n",
    "X_train2.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 Training the Linear Regression Model\n",
    "We train the model using the LinearRegression() function from scikit_learn. We are using the training set of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Selecting the linear regression method from the scikit-learn library\n",
    "model = LinearRegression().fit(X_train2, y_train2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 Predictions and Performance Evaluation\n",
    "This time we combined the prediction of the price using the data and we calculate the MAE and R2 values to evaluate the performnance.  The comparision data frame is also created to allow for an easy comparision with the results from the simple regression above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Validation\n",
    "# Evaluating the trained model on training data\n",
    "# MAE is relative depending on the scale of the data. The data scale for X ,y is two digits, so \n",
    "#The best possible score is 1 which is obtained when the predicted values are the same as the actual values.\n",
    "print(f\"The average carat size of diamonds in data {M_diamond['carat'].mean():.4f}\")\n",
    "print(f\"The average price of diamonds in the data {M_diamond['price'].mean():.2f}\")\n",
    "\n",
    "# Generate the predictions\n",
    "y_prediction_train2 = model.predict(X_train2)\n",
    "y_prediction_test2 = model.predict(X_test2)\n",
    "\n",
    "# Evaluating the trained model on both data sets\n",
    "print(\"MAE on multiple regression train data= \" , metrics.mean_absolute_error(y_train2, y_prediction_train2))\n",
    "print(\"MAE on multiple regression test data = \" , metrics.mean_absolute_error(y_test2, y_prediction_test2))\n",
    "print (\"R2 score on muliptle regression train data= \",metrics.r2_score(y_train2,y_prediction_train2))\n",
    "print (\"R2 score on muliptle regression test data= \",metrics.r2_score(y_test2,y_prediction_test2))\n",
    "\n",
    "\n",
    "#put the data into a dataframe to compare actual and predicted values, print 25 rows\n",
    "comparison_df2 = pd.DataFrame({\"Carat\":X_test2[\"carat\"],\"Actual\":y_test2, \"Predicted\":y_prediction_test2})\n",
    "comparison_df2.head(25)\n",
    "\n",
    "\n",
    "\n",
    "#print(y_prediction_train)\n",
    "#print(y_prediction_test)\n",
    "#print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results\n",
    "Looking at the results from the code box below, one can see the R2 scores were closer to 1 when multiple columns were used in the linear regression model. In addition, the MAE lowered which indicates our model had less variance when using the multiple linear regression model.\n",
    "\n",
    "Two bar charts were created using matplotlib. The values and labels were put into two separate lists. Titles were added and the bar chart was plotted for each value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 Score and MAE using metrics from scikit-learn - round to 4 decimal places.\n",
    "r2SimpleTrain = round(metrics.r2_score(y_train,y_prediction_train),4)\n",
    "r2SimpleTest = round(metrics.r2_score(y_test,y_prediction_test),4)\n",
    "r2MultiTrain =round(metrics.r2_score(y_train2,y_prediction_train2),4)\n",
    "r2MultiTest = round(metrics.r2_score(y_test2,y_prediction_test2),4)\n",
    "\n",
    "maeSimpleTrain = round(metrics.mean_absolute_error(y_train, y_prediction_train),4)\n",
    "maeSimpleTest = round(metrics.mean_absolute_error(y_test, y_prediction_test),4)\n",
    "maeMultiTrain = round(metrics.mean_absolute_error(y_train2, y_prediction_train2),4)\n",
    "maeMultiTest = round(metrics.mean_absolute_error(y_test2, y_prediction_test2),4)\n",
    "\n",
    "#Print the scores out \n",
    "print (f\"The R2 simple linear regression on training data : {r2SimpleTrain}\")\n",
    "print (f\"The R2 multiple regression on training data : {r2MultiTrain}\")\n",
    "print('\\n')\n",
    "print (f\"The R2 simple linear regression on test data : {r2SimpleTest}\")\n",
    "print (f\"The R2 multiple linear regression on test data : {r2MultiTest}\")\n",
    "print('\\n')\n",
    "print (f\"The MAE simple linear regression on training data : {maeSimpleTrain}\")\n",
    "print (f\"The MAE multiple linear regression on training data : {maeMultiTrain}\")\n",
    "print('\\n')\n",
    "print (f\"The MAE multiple linear regression on training data : {maeMultiTest}\")\n",
    "print (f\"The MAE simple linear regression on test data : {maeSimpleTest}\")\n",
    "\n",
    "## Create two bar graphs to compare R2 and MAE scores from simple to multi linear regression\n",
    "# Put all values and labels into lists\n",
    "r2Values=[r2SimpleTrain, r2MultiTrain, r2SimpleTest, r2MultiTest]\n",
    "r2ValueLabels = ['R2 Simp Train','R2 Mult Train',  'R2 Simp Test','R2 Mult Test']\n",
    "maeLabels=['MAE Simp Train', 'MAE Mult Train', 'MAE Simp Test','MAE Mult Test']\n",
    "maeValues =[maeSimpleTrain, maeMultiTrain, maeSimpleTest, maeMultiTest]\n",
    "\n",
    "\n",
    "# Create the first bar chart for R2\n",
    "bars = plt.bar(r2ValueLabels, r2Values, width=0.4)\n",
    "bars[0].set_color('green')\n",
    "bars[1].set_color('green')\n",
    "bars[2].set_color('blue')\n",
    "bars[3].set_color('blue')\n",
    "# Loop to put the centered data values on top of the bars\n",
    "for i in range(len(r2ValueLabels)):\n",
    "    plt.text(i,r2Values[i],r2Values[i], ha='center')\n",
    "#Titles and labels for chart    \n",
    "plt.suptitle('R2 test results - Simple vs. Multiple Linear Regression')\n",
    "plt.title(\"Higher values reflect higher accuracy\")\n",
    "plt.xlabel('R2 Results')\n",
    "plt.show()\n",
    "\n",
    "# Create the second chart for MAE\n",
    "bars = plt.bar(maeLabels, maeValues, width=0.4)\n",
    "bars[0].set_color('green')\n",
    "bars[1].set_color('green')\n",
    "bars[2].set_color('blue')\n",
    "bars[3].set_color('blue')\n",
    "# Loop to put the centered data values on top of the bars\n",
    "for i in range(len(maeLabels)):\n",
    "    plt.text(i,maeValues[i],maeValues[i], ha='center')\n",
    "#Titles and labels for chart\n",
    "plt.suptitle('MAE test results - Simple vs. Multiple Linear Regression')\n",
    "plt.title(\"Lower values reflect less variance in the model\")\n",
    "plt.xlabel('MAE Results')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='references'></a>\n",
    "### References and sources\n",
    "Data Source :   \n",
    "https://www.kaggle.com/datasets/swatikhedekar/price-prediction-of-diamond/data\n",
    "\n",
    "Basic Regression test sample:   \n",
    "https://www.educative.io/blog/machine-learning-regression-models-with-python\n",
    "\n",
    "Code to prepare categorical data:   \n",
    "https://www.kaggle.com/code/amirulabdlatib/diamond-price-prediction \n",
    "\n",
    "Matplotlib plotting:   \n",
    "https://www.geeksforgeeks.org/bar-plot-in-matplotlib/   \n",
    "https://statisticsbyjim.com/regression/interpret-r-squared-regression/   \n",
    "https://www.geeksforgeeks.org/plot-a-horizontal-line-in-matplotlib/   \n",
    "https://bobbyhadz.com/blog/matplotlib-add-average-line-to-plot#:~:text=Use%20the%20pyplot.,data%20coordinates%20as%20a%20parameter   \n",
    "https://www.geeksforgeeks.org/adding-value-labels-on-a-matplotlib-bar-chart/\n",
    "\n",
    "\n",
    "R2 :   \n",
    "https://statisticsbyjim.com/regression/interpret-r-squared-regression/\n",
    "\n",
    "Multicollinearity:   \n",
    "https://www.analyticsvidhya.com/blog/2020/03/what-is-multicollinearity/\n",
    "\n",
    "\n",
    "Go back to [Top](#top)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
