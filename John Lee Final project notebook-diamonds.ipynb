{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "# Diamond Price - A Linear Regression Model\n",
    "### Table of Contents\n",
    "| Simple Linear Regression                                                                        |  Multiple Linear Regresssion                                                     |\n",
    "| ------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------|\n",
    "| [Introduction](#intro)                                                                          |   [Introduction](#multi)                                                         |\n",
    "| [Step 1](#step1) - Importing the libraries needed to process the data and the regression model  |   [Step 1](#stepm1) - Read In a New Dataframe                                    |\n",
    "| [Step 2](#step2) - Importing the data to a dataframe                                            |   [Step 2](#stepm2) - Data Preparation                                           |\n",
    "| [Step 3](#step3) - Exploring the data frame                                                     |   [One-hot Encoding](#one-hot) - converting categorical data to numerical values | \n",
    "| [Step 4](#step4) - Assigning X and y - Feature and Target                                       |   [Step 3](#stepm3) - Assigning X and y - Feature and Target                     |\n",
    "| [Step 5](#step5) - Dividing the data Into two sets - Train and Test                             |   [Step 4](#stepm4) - Dividing the Data Into Sets - Train and Test               |\n",
    "| [Step 6](#step6) - Training the Linear Regression Model                                         |   [Step 5](#stepm5) - Training the Linear Regression Model                       |  \n",
    "| [Step 7](#step7) - Predicting the Diamond price                                                 |   [Step 6](#stepm6) - Predictions and Performance Evaluation                     |\n",
    "| [Step 8](#step8) - Evaluating the performance of the model                                      |   [Final Results](#finalm)                                                       |\n",
    "| [Step 9](#step9) - Graphing the data and regression line                                        |                                                                                  |\n",
    "| [Results](#results)                                                                             |                                                                                  |\n",
    "| [References](#references)                                                                       |                                                                                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Diamonds\n",
    "\n",
    "This is a regression model built to predict a diamond's price based on different characteristics of a diamond. \n",
    "\n",
    "It starts with simple linear regression model. The model will try to use a single indepdent variable (in this case the carat size) to predict a dependent variable (price of the diamond) as this seems to make sense, the larger the carat size the more expensive it should be. \n",
    "\n",
    "Using the data provided by Kaggle, the data is a single comma-seprated file (csv) with the following characteristics:\n",
    "\n",
    "- A data frame with 53940 rows and 10 variables:\n",
    "- price: price in US dollars (\\$326--\\$18,823)\n",
    "- carat: weight of the diamond (0.2--5.01)\n",
    "- cut: quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n",
    "- color: diamond colour, from J (worst) to D (best)\n",
    "- clarity: a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
    "- x: length in mm (0--10.74)\n",
    "- y: width in mm (0--58.9)\n",
    "- z: depth in mm (0--31.8)\n",
    "- depth: total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79)\n",
    "- table: width of top of diamond relative to widest point (43--95)\n",
    "\n",
    "Further description and download link can be found in the [references](#references) section of this notebook\n",
    "\n",
    "\n",
    "Back to [TOC](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1 - Importing the libraries needed to process the data and the regression model\n",
    "\n",
    "- pandas - Python library used to process data. We will put the data into a pandas dataframe to prepare the data for our regression test.\n",
    "- matplotlib - library used to generate a plot in Python. We will generate a scatter plot and the regression line using this library\n",
    "- Sklearn - this is the libary used for machine learning in Python. It is called scikitl-learn. It contains the functions and methods to:\n",
    "    - Split data to train and test\n",
    "    - Linear regression test\n",
    "    - Metrics to evaluate the model\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Importing libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2 - Importing the data to a dataframe\n",
    "Referring to the documentation for the data, and reviewing the csv file to find the format of the data is important\n",
    "\n",
    "- The variable Diamond is used to point to the dataframe created by reading the csv into memory using pandas\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: reading in the csv and creating the DataFrame \n",
    "\n",
    "Diamond = pd.read_csv('diamonds.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3 - Exploring the data frame\n",
    "Exploring the data frame created will ensure our data is complete and usuable for our model.  We can extract some information about the data by using the following methods:\n",
    "\n",
    "\n",
    "- .info() - prints information about the data: \n",
    "    - number of columns\n",
    "    - column labels\n",
    "    - data types **\n",
    "    - range index - how many rows of data\n",
    "    \n",
    "A good way to get some statistics on the data we are using\n",
    "- .describe() - quick calculation of the data \n",
    "    - count - not empty values\n",
    "    - mean - average\n",
    "    - std - standard deviation\n",
    "    - min - minimum value\n",
    "    - 25% - 25% percentile\n",
    "    - 50% - 50% percentile\n",
    "    - 75% - 75% percential\n",
    "    - max - maximum value\n",
    "\n",
    "- .head() - small snapshot of the data. The first 5 rows if a number is not specified.\n",
    "- .isna() - show any missing values denoted as NaN by Pandas.\n",
    "- .corr() - cross-correlation matrix - show how closely related our X and y are. We use this table to find a good correlation between our independant and dependant variables (X and y). \n",
    "\n",
    "** As shown in the output of .info()  the data returned three types, int64, float64 and object. Since regression can only use numeric data, we should be aware cut, color, clarity cannot be used as it. More on this later in the notebook. \n",
    "\n",
    "\n",
    "Go back to [TOC](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing .info() and .describe to view info on the dataframe\n",
    "print(\"Printing some information about the data using .info():\\n\")\n",
    "Diamond.info()\n",
    "print(\"\\n The data description using .describe():\")\n",
    "Diamond.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small snapshot of the data using the .head() method\n",
    "- .head() - method in pandas used to return a few rows of the data. If a number is not specified, return the first 5 rows. We will use this again later for data comparision. Notice cut color and categoric features (non-numeric) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Printing 5 rows of the data:\")\n",
    "Diamond.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make sure this data is complete and does not have any missing values. Using the .isna() method will show any missing values denoted as NaN by Pandas.  All zeros in the right column means there is data in each row for the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking foir NaN - missing data\n",
    "Diamond.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the cross correlation matrix. - Since we only want to do a simple regression test, we want to try the find the independant variable that is closest to the price of the diamond. By running the .corr() method , Pandas will show us the relationship between the columns in the dataframe. The higher the number the closer the columns are related to each other. Only numeric values are shown in this matrix. We will look at the categorical (non-numeric) data later in part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the cross-correlation matrix - Looking for two correlated values. \n",
    "print(Diamond.corr(numeric_only = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The correlation matrix above shows that price is closely related to carat which indicates this may be a good relationship to use for our regresssion model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step4'></a>\n",
    "## Step 4 - Assigning X and y - Feature and Target \n",
    "We need the independent variable and dependent variables assigned. X is independent and y is dependent. we are going to use X to predict y   \n",
    "X = adding carat to the feature matrix   \n",
    "y = adding price as the target variable \n",
    "\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Assigning our feature (X) and target variable (y)\n",
    "#Using the carat of the diamond (X) to predict the price (y)\n",
    "X = Diamond[['carat']]\n",
    "y = Diamond['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step5'></a>\n",
    "## Step 5 - Dividing the Data Into Sets - Train and Test\n",
    "we want to take our data and divide it into two sets, train and test. We will use our train set to train the model and use the test set afterwards. 70% of the data will be used to train the model with 30% used as the test data set.  Using a the random_state option sets a seed so that we can recreate the same test with same results. shuffle will shuffle the data before it splits so we get a good representation of the data without introducing a bias such as the order of the data into our sets. Train_test_split() is a function of scikit-learn\n",
    "\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Dividing the dataset into test and train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step6'></a>\n",
    "## Step 6 - Training the Linear Regression Model\n",
    "We train the model using the LinearRegression() function from scikit_learn. We are using the training set of data.\n",
    "\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Selecting the linear regression method from the scikit-learn library\n",
    "model = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step7'></a>\n",
    "## Step 7 - Predicting the Diamond price\n",
    "\n",
    "Using the .predict() from scikit-learn, we are predicting y based on the X_train and X_test datasets. This will allow us to calculate the performance of the model for both training and test data. \n",
    "\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Predicting the diamonds price from training and test data\n",
    "y_prediction_train = model.predict(X_train)\n",
    "y_prediction_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step8'></a>\n",
    "## Step 8 - Evaluating the performance of the model\n",
    "After predicting the diamond's price in step 7. We want to see how our model performs. We are going to use the **R2** score and the **Mean Absolute Error (MAE)** as indications of how well our simple Linear Regression model can predict the price of a diamond using only the carat size.\n",
    "\n",
    "-  The R2 score is the percentage of the variance in the dependent variable that the independant variable explains. In other words how well did the carat size predict the price of the diamond. The closer to 1 theoretically the better the model fit. If the R2 score is less than .9, we will likely have to consider using more features to predict y.   \n",
    "-  MAE will show us how \"off\" our model is. Because the diamond prices can vary even if they are the same carat size, MAE was chosen because it is less sensitve to outliers. The lower the MAE, the closer the predictions are to the actual values.\n",
    "\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8:  Evaluation\n",
    "# Evaluating the trained model on training data. R2 and MAE calculations are from scikit-learn\n",
    "\n",
    "print(f\"The average carat size of diamonds in data {Diamond['carat'].mean()}\")\n",
    "print(f\"The average price of diamonds in the data {Diamond['price'].mean()}\")\n",
    "\n",
    "print (\"R2 score on train data= \",metrics.r2_score(y_train,y_prediction_train))\n",
    "print (\"R2 score on test data= \",metrics.r2_score(y_test,y_prediction_test))\n",
    "print(\"MAE on train data= \" , metrics.mean_absolute_error(y_train, y_prediction_train))\n",
    "print(\"MAE on test data = \" , metrics.mean_absolute_error(y_test, y_prediction_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step9'></a>\n",
    "## Step 9 - Graphing the data and regression line\n",
    "We will use matplotlib to produce a scatter plot of both sets of data and also plot the regeression line for both test and train data sets.  Reference lines for the average carat size (X) and price (y) were added as an observation point\n",
    "\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test, y_test, color='b', label='Actual Data')\n",
    "plt.plot(X_test, y_prediction_test, color='r', label='Regression Line')\n",
    "plt.axvline(x=np.nanmean(X_test),color='c',linestyle='--', label ='Avg Carat Size \\'X test\\'')\n",
    "plt.axhline(y=np.nanmean(y_test),color='g',linestyle='--', label ='Avg price \\'y test\\'')\n",
    "plt.xlabel('Carat Size')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.title('Linear Regression Test Data')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(X_train, y_train, color='b', label='Training Data')\n",
    "plt.plot(X_train, y_prediction_train, color='r', label='Regression Line')\n",
    "plt.axvline(x=np.nanmean(X_train),color='c',linestyle='--', label ='Avg Carat Size \\'X train\\'')\n",
    "plt.axhline(y=np.nanmean(y_train),color='g',linestyle='--', label ='Avg price \\'y train\\'')\n",
    "plt.xlabel('Carat Size')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.title('Linear Regression Training Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For and easy reference, we created a dataframe using the actual values of price and carat size from the data and the predicted value from the regression model. This is an easy way to visually examine the accuracy of the model. As mentioned in step 3, we will use .head() to print out the first 25 rows of the data. Alternatively, we can use .iloc[] in pandas to select a range of rows to print out. The code box below has commented instruction to use .iloc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#put the data into a dataframe to compare actual and predicted values, print 25 rows\n",
    "#comparison_df = pd.DataFrame({\"Actual\":y_test, \"Predicted\":y_prediction_test}) \n",
    "\n",
    "comparison_df = pd.DataFrame({\"Carat\": X_test['carat'], \"Actual y\":y_test, \"Predicted y \":y_prediction_test}) \n",
    "comparison_df.head(15)\n",
    "\n",
    "# comment out the line above and uncomment the line below to print different sections of the dataframe. Adjust the range for the section of data to print. \n",
    "#print (comparison_df.iloc[25:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='results'></a>\n",
    "# Results \n",
    "Our results above indicates a only fairly accurate model based soley on the carat size to predict the price.  The intersection of the mean of X and mean of y directly on the regression line gives us an indication of a fairly accurate mode since the intersection point represents the value of y when X is at its average.The R2 score indicates this is a fairly accurate model but as noted above the score is less than .9. The MAE indicated our model is off about ~1000 average.   We are in the ballpark but there is more work to be done. Looking at the actual and predicted results, We can see some predicted values are within twenty dollars on some diamonds and off by thousands on others.   Interpretation of the MAE is relative to the data. Diamonds in our dataset have an average price of $3932 , so to be off by ~1000 isn't a terrific result. The combination of a R2 score < .9 and a somewhat high MAE will lead us to perform a multiple linear regression in part 2 to see if the model is more accurate when including other features.  We will compare the R2 and MAE from both models and see if our model is more accurate when using a larger feature matrix.\n",
    "\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='multi'></a>\n",
    "## Introduction - Multiple Linear Regression\n",
    "Since our model above had some larger variances in the results, an R2 score <.9 and MAE ~1000, can we get the model to be more accurate? One way we can try to do this is to include more features in the data and see if these additional features affect the accuracy of the model.  We will use a multiple linear regression and add in variables which we beleive would affect the price of a diamond. \n",
    "\n",
    "Read more about how a diamond is graded and ultimately priced: https://www.gemsociety.org/article/a-consumers-guide-to-gem-grading/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*To keep the dataframes separate, we will import the data into a different dataframe called M_diamond.  We will also have to prepare the data to include the categorical features cut, color , clarity as these seem important when deciding the price of a diamond.\n",
    "\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='stepm1'></a>\n",
    "## Step 1 - Read In a New Dataframe\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seading the DataFrame and printing a few lines data fraome. \n",
    "\n",
    "M_diamond = pd.read_csv('diamonds.csv')\n",
    "M_diamond.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column 'Unnamed: 0' isn't necessary as it seems like it is just a row indicator. The dataframe will also have a column to indicated the rows, so we will drop this column from the dataframe as we do not want to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the Unnamed: 0 column\n",
    "M_diamond.drop('Unnamed: 0', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='stepm2'></a>\n",
    "## Step 2 - Data Preparation\n",
    "\n",
    "This time we need to prepare the data by converting the categorical features into numerical values. In order to do this, we will extract the unique answers from each of the columns (color and clarity) and create additional columns in the dataframes with the unique answers. After the columns are created, for each diamond,  we will populate the appropriate cell with a boolean (True or False) to indicate which of the characteristics the diamond has. Once this is completed, we will replace the True and False values with integers 1 and 0 respectively\n",
    "\n",
    "For example, take the color of a diamond. Each diamond is graded against a scale which contains seven colors (E,I,J,H,F,G,D).  We wiill expand the dataframe to include one column for each of the color grades. If a diamond is graded an 'E' in color, the dataframe will contain a 'True' in the new 'E' column and 'False' for the other columns (I,J,H,F,G,D). This ensures we have accounted for the color with a boolean value. We will apply the same concept for clarity by expanding the dataframe with an additional eight columns (one for each clarity grade). The True and False values will then be replaced by integer 1 and 0 respectively.\n",
    "\n",
    "The cut rating of a diamond is ordinal which means it is a hierarchal scale.  The best thing to do with this is to directly replace each cut rating with a numeric value scale as follows. This differs from the color and clarity as their values do not make up a hierarchal scale, but rather just a rating system.\n",
    "The cut scale will be replaced as:\n",
    "- Fair = 0\n",
    "- Good - 1\n",
    "- Very Good = 2\n",
    "- Premium = 3\n",
    "- Ideal = 4\n",
    "\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking to identify the columns which contain categorical features. \n",
    "M_diamond.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code box below, we are iterating through the data frame columns which contain objects as datatypes\n",
    "the for loop controls the iteration for each column. The if statement will print the column name and the unique values in the column if the column's datatype is 'object'\n",
    "\n",
    "This will give us the unique names we need to add the columns for color and clarity. It also shows the unique values for the rating scale for cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in M_diamond:\n",
    "    if M_diamond[col].dtypes=='object':\n",
    "        print(f'{col} : {M_diamond[col].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='one-hot'></a>\n",
    "## One-hot Encoding\n",
    "The code box below is using  one-hot encoding to convert each of the unique values we identified above to a boolean datatype (True or False). This technique involves using a new dataframe called 'dummies' and  using the 'get_dummies' function from Pandas.  As noted above, we will peform this for the 'color' and 'clarity' columns.\n",
    "\n",
    "The concept of Multicollinearity can occur when using the one-hot encoding. This means that two or more of the new independent variables we are creating have a high correlation with one another in the model. This condition makes it difficult to identify the effect of each variable's effect on the dependent variable. They are simply too closely related. When using dummy variables the dummy variable trap can occur in which one dummy variable can be predicted from the others. We will drop one of the dummy variables. the 'drop_first = True' option below will drop the first level of variable. Compare the output of 'dummies.dtypes' below to the unique object values from above. One unique value was dropped from 'cut' and one from 'clarity'\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(M_diamond[['color','clarity']],drop_first=True)\n",
    "dummies.dtypes, print(f\"A few lines of the new dataframe \\n {dummies.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the header output above, we can see the results of the 'get_dummies' function created the new boolean columns, but the values are not numeric. The values in the columns are set the \"True\" if the diamond in the row is rated a particular color or clarity rating and 'False' for the remaining respective columns. The next codebox uses the .replace() method to replace 'True' with a '1' and 'False' with a '0' and set the type as integer. This is the final step for color and clarity columns. observe the output from the box below. All of the values are now '1' or '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in dummies:\n",
    "    dummies[col] = dummies[col].replace({'True':1,'False':0}).astype(int)\n",
    "    \n",
    "dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dummies dataframe is complete for color and clarity, we will now concatenate the dummies df with our M_diamond dataframe. Also drop the categorical 'color' and 'clarity' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the two dataframes together as noted in above Markdown box. \n",
    "M_diamond = pd.concat([M_diamond,dummies],axis=1)\n",
    "M_diamond.drop(['color','clarity'],axis=1,inplace=True)\n",
    "M_diamond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final column to fix is to replace the cut column with a numeric scale. \n",
    "We first look at the unique values in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_diamond.cut.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use .replace() again to replace the values as follows:\n",
    "- Fair = 0\n",
    "- Good - 1\n",
    "- Very Good = 2\n",
    "- Premium = 3\n",
    "- Ideal = 4\n",
    "\n",
    "We print the info for the dataframe to confirm all columns are now numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the values in cut with numeric scale and disply the data type for each column\n",
    "M_diamond['cut'] = M_diamond['cut'].replace({'Fair':0,'Good':1,'Very Good':2,'Premium':3,'Ideal':4})\n",
    "M_diamond.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the cross-correlation matrix - Looking for additional  correlated values. \n",
    "print(M_diamond.corr(numeric_only = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='stepm3'></a>\n",
    "## Step 3 - Assigning X and y - Feature and target\n",
    "We need the independent variable and dependent variables reassigned. X is independent and y is dependent. we are going to use X to predict y\n",
    "X = drop the price column and use all of the remaining columns. This increases the feature matrix from the previous simple regression. \n",
    "y = adding price as the target variable \n",
    "\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Seperating the data into features and labels\n",
    "\n",
    "X = M_diamond.drop('price',axis=1) # Independent variable Drop price and keep everything else\n",
    "y = M_diamond['price'] # dependent variable\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='stepm4'></a>\n",
    "## Step 4 Dividing the Data Into Sets - Train and Test\n",
    "we want to take our data and divide it into two sets, train and test. We will use our train set to train the model and use the test set afterwards. 70% of the data will be used to train the model with 30% used as the test data set.  Using a the random_state option sets a seed so that we can recreate the same test with same results. shuffle will shuffle the data before it splits so we get a good representation of the data without introducing a bias such as order of the data into our sets. train_test_split(0 is a function of scikit-learn\n",
    "\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Dividing the dataset into test and train data\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.3, random_state=10, shuffle=True)\n",
    "X_train2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='stepm5'></a>\n",
    "## Step 5 - Training the Linear Regression Model\n",
    "We train the model using the LinearRegression() function from scikit_learn. We are using the training set of data \n",
    "\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Selecting the linear regression method from the scikit-learn library\n",
    "model = LinearRegression().fit(X_train2, y_train2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='stepm6'></a>\n",
    "## Step 6 - Predictions and Performance Evaluation\n",
    "This time we combined the prediction of the price using the data and we calculate the MAE and R2 values to evaluate the performnance.  The comparision data frame is also created to allow for an easy comparision with the results from the simple regression above\n",
    "\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Validation\n",
    "# Evaluating the trained model on training data\n",
    "# MAE is relative depending on the scale of the data. The data scale for X ,y is two digits, so \n",
    "#The best possible score is 1 which is obtained when the predicted values are the same as the actual values.\n",
    "print(f\"The average carat size of diamonds in data {M_diamond['carat'].mean():.4f}\")\n",
    "print(f\"The average price of diamonds in the data {M_diamond['price'].mean():.2f}\")\n",
    "\n",
    "# Generate the predictions\n",
    "y_prediction_train2 = model.predict(X_train2)\n",
    "y_prediction_test2 = model.predict(X_test2)\n",
    "\n",
    "# Evaluating the trained model on both data sets\n",
    "print(\"MAE on multiple regression train data= \" , metrics.mean_absolute_error(y_train2, y_prediction_train2))\n",
    "print(\"MAE on multiple regression test data = \" , metrics.mean_absolute_error(y_test2, y_prediction_test2))\n",
    "print (\"R2 score on muliptle regression train data= \",metrics.r2_score(y_train2,y_prediction_train2))\n",
    "print (\"R2 score on muliptle regression test data= \",metrics.r2_score(y_test2,y_prediction_test2))\n",
    "\n",
    "\n",
    "#put the data into a dataframe to compare actual and predicted values, print 25 rows\n",
    "comparison_df2 = pd.DataFrame({\"Carat\":X_test2[\"carat\"],\"Actual\":y_test2, \"Predicted\":y_prediction_test2})\n",
    "comparison_df2.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='finalm'></a>\n",
    "# Final Results\n",
    "Looking at the results from the code box below, one can see the R2 scores for the multiple linear regression model were above .9 and the MAE lowered which indicates our model had less variance when using the multiple linear regression model. Overall, the multiple linear regression model was more accurate in predicting the price of a diamond than the simple linear regression. This model aligns with how the diamond industry grades and subsequently prices its diamonds (See the diamond article in the [references](#references) section). The carat, cut, color and clarity all have an effect the price of the diamond. \n",
    "\n",
    "Two bar charts were created using matplotlib. The values and labels were put into two separate lists. Titles were added and the bar chart was plotted for each value. Please see the comments in the code box for additional Python syntax detail.\n",
    "\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 Score and MAE using metrics from scikit-learn - round to 4 decimal places.\n",
    "r2SimpleTrain = round(metrics.r2_score(y_train,y_prediction_train),4)\n",
    "r2SimpleTest = round(metrics.r2_score(y_test,y_prediction_test),4)\n",
    "r2MultiTrain =round(metrics.r2_score(y_train2,y_prediction_train2),4)\n",
    "r2MultiTest = round(metrics.r2_score(y_test2,y_prediction_test2),4)\n",
    "\n",
    "maeSimpleTrain = round(metrics.mean_absolute_error(y_train, y_prediction_train),4)\n",
    "maeSimpleTest = round(metrics.mean_absolute_error(y_test, y_prediction_test),4)\n",
    "maeMultiTrain = round(metrics.mean_absolute_error(y_train2, y_prediction_train2),4)\n",
    "maeMultiTest = round(metrics.mean_absolute_error(y_test2, y_prediction_test2),4)\n",
    "\n",
    "#Print the scores out \n",
    "print (f\"The R2 simple linear regression on training data : {r2SimpleTrain}\")\n",
    "print (f\"The R2 multiple regression on training data : {r2MultiTrain}\")\n",
    "print('\\n')\n",
    "print (f\"The R2 simple linear regression on test data : {r2SimpleTest}\")\n",
    "print (f\"The R2 multiple linear regression on test data : {r2MultiTest}\")\n",
    "print('\\n')\n",
    "print (f\"The MAE simple linear regression on training data : {maeSimpleTrain}\")\n",
    "print (f\"The MAE multiple linear regression on training data : {maeMultiTrain}\")\n",
    "print('\\n')\n",
    "print (f\"The MAE multiple linear regression on training data : {maeMultiTest}\")\n",
    "print (f\"The MAE simple linear regression on test data : {maeSimpleTest}\")\n",
    "\n",
    "## Create two bar graphs to compare R2 and MAE scores from simple to multi linear regression\n",
    "# Put all values and labels into lists\n",
    "r2Values=[r2SimpleTrain, r2MultiTrain, r2SimpleTest, r2MultiTest]\n",
    "r2ValueLabels = ['R2 Simp Train','R2 Mult Train',  'R2 Simp Test','R2 Mult Test']\n",
    "maeLabels=['MAE Simp Train', 'MAE Mult Train', 'MAE Simp Test','MAE Mult Test']\n",
    "maeValues =[maeSimpleTrain, maeMultiTrain, maeSimpleTest, maeMultiTest]\n",
    "\n",
    "\n",
    "# Create the first bar chart for R2\n",
    "bars = plt.bar(r2ValueLabels, r2Values, width=0.4)\n",
    "bars[0].set_color('green')\n",
    "bars[1].set_color('green')\n",
    "bars[2].set_color('blue')\n",
    "bars[3].set_color('blue')\n",
    "# Loop to put the centered data values on top of the bars\n",
    "for i in range(len(r2ValueLabels)):\n",
    "    plt.text(i,r2Values[i],r2Values[i], ha='center')\n",
    "#Titles and labels for chart    \n",
    "plt.suptitle('R2 test results - Simple vs. Multiple Linear Regression')\n",
    "plt.title(\"Higher values reflect higher accuracy\")\n",
    "plt.xlabel('R2 Results')\n",
    "plt.show()\n",
    "\n",
    "# Create the second chart for MAE\n",
    "bars = plt.bar(maeLabels, maeValues, width=0.4)\n",
    "bars[0].set_color('green')\n",
    "bars[1].set_color('green')\n",
    "bars[2].set_color('blue')\n",
    "bars[3].set_color('blue')\n",
    "# Loop to put the centered data values on top of the bars\n",
    "for i in range(len(maeLabels)):\n",
    "    plt.text(i,maeValues[i],maeValues[i], ha='center')\n",
    "#Titles and labels for chart\n",
    "plt.suptitle('MAE test results - Simple vs. Multiple Linear Regression')\n",
    "plt.title(\"Lower values reflect less variance in the model\")\n",
    "plt.xlabel('MAE Results')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='references'></a>\n",
    "### References and sources\n",
    "Data Source :   \n",
    "https://www.kaggle.com/datasets/swatikhedekar/price-prediction-of-diamond/data\n",
    "\n",
    "Basic Regression test sample:   \n",
    "https://www.educative.io/blog/machine-learning-regression-models-with-python\n",
    "\n",
    "Code to prepare categorical data:   \n",
    "https://www.kaggle.com/code/amirulabdlatib/diamond-price-prediction \n",
    "\n",
    "Matplotlib plotting:   \n",
    "https://www.geeksforgeeks.org/bar-plot-in-matplotlib/   \n",
    "https://statisticsbyjim.com/regression/interpret-r-squared-regression/   \n",
    "https://www.geeksforgeeks.org/plot-a-horizontal-line-in-matplotlib/   \n",
    "https://bobbyhadz.com/blog/matplotlib-add-average-line-to-plot#:~:text=Use%20the%20pyplot.,data%20coordinates%20as%20a%20parameter   \n",
    "https://www.geeksforgeeks.org/adding-value-labels-on-a-matplotlib-bar-chart/\n",
    "\n",
    "\n",
    "R2 :   \n",
    "https://statisticsbyjim.com/regression/interpret-r-squared-regression/\n",
    "\n",
    "Multicollinearity:   \n",
    "https://www.analyticsvidhya.com/blog/2020/03/what-is-multicollinearity/\n",
    "\n",
    "Diamond Pricing:   \n",
    "https://www.gemsociety.org/article/a-consumers-guide-to-gem-grading/\n",
    "\n",
    "\n",
    "Go back to [TOC](#top)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
